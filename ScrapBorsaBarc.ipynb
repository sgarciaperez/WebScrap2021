{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "monthly-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primerament importem totes les llibreries necessaries per completar el projecte.\n",
    "import os\n",
    "import requests\n",
    "import argparse\n",
    "import csv\n",
    "import pathlib \n",
    "import time\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carreguem el fitxer de configuració a la variable config:\n",
    "with open(\"configuration.json\", \"r\") as configFile:\n",
    "    config = json.load(configFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "developed-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Funcions per obtindre la llista del indexs del Ibex 35 de la borsa de Barcelona\n",
    "\n",
    "# Get Header\n",
    "def getHeaders():   \n",
    "    return config['header']\n",
    "\n",
    "\n",
    "# Get table Page        \n",
    "def getPageTable(UrlPage):        \n",
    "    table = None\n",
    "    try:\n",
    "        # Data for post form    \n",
    "        data = {'punto':'indice'}    \n",
    "        page = requests.post(UrlPage,timeout=10)    \n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "        table = soup.find('table', attrs={'id': 'ctl00_Contenido_tblAcciones'})                           \n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"Timeout a la càrrega de la web\")\n",
    "    except:        \n",
    "        print(\"Error inesperat\")\n",
    "    return table        \n",
    "\n",
    "# Get Firm page and wait x seconds\n",
    "def getFirmTablePage(UrlFirmPage):    \n",
    "    table = None    \n",
    "    try:\n",
    "        t0 = time.time()\n",
    "        # Data for post form            \n",
    "        data = {'punto':'indice'}    \n",
    "        page = requests.get(UrlFirmPage,timeout=10)                    \n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")                \n",
    "        table = soup.find('table', attrs={'id': 'ctl00_Contenido_tblCapital'})                           \n",
    "        # Wait time depending of response\n",
    "        response_delay = time.time() - t0     \n",
    "        time.sleep(10 * response_delay)\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"-->Timeout a la càrrega de dada de la companyia\")                \n",
    "    except:                \n",
    "        print(\"-->Error inesperat: \" +  UrlFirmPage)\n",
    "    return table\n",
    "\n",
    "# Get the list of firm interesting values\n",
    "def getFirmValues(UrlBase,firmPage):\n",
    "    Url = UrlBase+firmPage        \n",
    "    values = []\n",
    "    table = getFirmTablePage(Url)        \n",
    "    if (table is not None):                \n",
    "        nroFila=0\n",
    "        rowNum=0\n",
    "        for row in table.find_all(\"tr\"):\n",
    "            if rowNum==1:\n",
    "                colNum=0                \n",
    "                for cell in row.find_all('td'):\n",
    "                    if colNum==1:\n",
    "                        value=[cell.text,\"\"]              \n",
    "                        values.append(value)                                \n",
    "                        break;\n",
    "                    colNum=colNum+1\n",
    "            rowNum=rowNum+1       \n",
    "    return values\n",
    "\n",
    "# Set List with table page values\n",
    "def getIndexs(UrlBase,UrlRef,bTableHead):\n",
    "    indexList = []\n",
    "    UrlIndexPage = UrlBase+UrlRef\n",
    "    table = getPageTable(UrlIndexPage)    \n",
    "    # Extract table values and links\n",
    "    rowList = []\n",
    "    for tr in table.find_all(\"tr\"):        \n",
    "        colList = []               \n",
    "        valuesFirm = []\n",
    "        # Cells Header\n",
    "        cellsHead = tr.findAll('th')                \n",
    "        if ((cellsHead is not None) and (len(cellsHead) > 0)):\n",
    "            if (bTableHead):\n",
    "                for cellHead in cellsHead:        \n",
    "                    value = [cellHead.text.strip(),'']                  \n",
    "                    colList.append(value)                                                   \n",
    "                colList.append(['Capitalización',''])\n",
    "        else:\n",
    "            # Cells value\n",
    "            cells = tr.findAll('td')                        \n",
    "            for cell in cells:\n",
    "                href = ''\n",
    "                infComp = []\n",
    "                a= cell.find('a')                  \n",
    "                if (a is not None):                 \n",
    "                    href = a.get('href')                                \n",
    "                    # Append / if needed\n",
    "                    if href[0] !='/':\n",
    "                        href = '/' + href                     \n",
    "                    valuesFirm = getFirmValues(UrlBase,href) \n",
    "                    # print firm\n",
    "                    print(cell.text)\n",
    "                value = [cell.text.strip(),href]                                  \n",
    "                colList.append(value)             \n",
    "                \n",
    "        # Extend list with firm information \n",
    "        colList.extend(valuesFirm)        \n",
    "        # Append to rowlist    \n",
    "        rowList.append(colList)         \n",
    "    return rowList \n",
    "\n",
    "\n",
    "def writecsv(table,filename):\n",
    "    currentDir = os.path.abspath('')\n",
    "    filePath = os.path.join(currentDir,filename)\n",
    "    file = open(filePath,\"a+\")\n",
    "    for row in table:\n",
    "        for col in row:\n",
    "            file.write(col[0]+\";\")\n",
    "        file.write(\"\\n\")\n",
    "    \n",
    "# Extract all information of the Stock Exchange at any time\n",
    "def SaveOneDayInfo(fileName,bTabHeader):\n",
    "    indexList = getIndexs(config['URLs']['base'], config['URLs']['ref'], bTabHeader);       \n",
    "    # Check end of Stock Exchange session\n",
    "    bEndSession = False    \n",
    "    if (indexList is not None):        \n",
    "        posRow = 0\n",
    "        if (bTabHeader): posRow = 1            \n",
    "        HourSession = str(indexList[posRow][8][0])            \n",
    "        bEndSession  = (HourSession.strip() == 'Cierre')                \n",
    "    #save file\n",
    "    writecsv(indexList,fileName)            \n",
    "    #return state\n",
    "    return bEndSession        \n",
    "        \n",
    "# Save the Stock Exchange one day\n",
    "def ScheduleDayFile():\n",
    "    fileName = \"ListaIndices\" + time.strftime('%Y%m%d')+ \".csv\"\n",
    "    bEndSession = SaveOneDayInfo(fileName,True);\n",
    "    while (not bEndSession):            \n",
    "        print(\"Waiting 15 minutes\")\n",
    "        time.sleep(60*15)        \n",
    "        bEndSession = SaveOneDayInfo(fileName,False);    \n",
    "    print(\"End of session: file generated: \" + fileName)\n",
    "    \n",
    "# Save the Stock Exchange one week\n",
    "def ScheduleWeekFiles():    \n",
    "    scheduler = BlockingScheduler()    \n",
    "    scheduler.add_job(job_function, 'cron', day_of_week='mon-fri', hour=9, minute=0)    \n",
    "    scheduler.start()    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "numerical-enemy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ACCIONA\n",
      "ACERINOX\n",
      "ACS\n",
      "AENA\n",
      "ALMIRALL\n",
      "AMADEUS\n",
      "ARCELORMIT.\n",
      "B.SANTANDER\n",
      "BA.SABADELL\n",
      "BANKINTER\n",
      "BBVA\n",
      "CAIXABANK\n",
      "CELLNEX\n",
      "CIE AUTOMOT.\n",
      "ENAGAS\n",
      "ENDESA\n",
      "FERROVIAL\n",
      "FLUIDRA\n",
      "GRIFOLS CL.A\n",
      "IAG\n",
      "IBERDROLA\n",
      "INDITEX\n",
      "INDRA A\n",
      "INM.COLONIAL\n",
      "MAPFRE\n",
      "MELIA HOTELS\n",
      "MERLIN\n",
      "NATURGY\n",
      "PHARMA MAR\n",
      "R.E.C.\n",
      "REPSOL\n",
      "SIEMENS GAME\n",
      "SOLARIA\n",
      "TELEFONICA\n",
      "VISCOFAN\n"
     ]
    }
   ],
   "source": [
    "# indicar la ruta\n",
    "indexList = getIndexs(config['URLs']['base'], config['URLs']['ref'], True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "duplicate-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "writecsv(indexList, config[\"outputFile\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "proper-tennis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCIONA\n",
      "ACERINOX\n",
      "ACS\n",
      "AENA\n",
      "ALMIRALL\n",
      "AMADEUS\n",
      "ARCELORMIT.\n",
      "B.SANTANDER\n",
      "BA.SABADELL\n",
      "BANKINTER\n",
      "BBVA\n",
      "CAIXABANK\n",
      "CELLNEX\n",
      "CIE AUTOMOT.\n",
      "ENAGAS\n",
      "ENDESA\n",
      "FERROVIAL\n",
      "FLUIDRA\n",
      "GRIFOLS CL.A\n",
      "IAG\n",
      "IBERDROLA\n",
      "INDITEX\n",
      "INDRA A\n",
      "INM.COLONIAL\n",
      "MAPFRE\n",
      "MELIA HOTELS\n",
      "MERLIN\n",
      "NATURGY\n",
      "PHARMA MAR\n",
      "R.E.C.\n",
      "REPSOL\n",
      "SIEMENS GAME\n",
      "SOLARIA\n",
      "TELEFONICA\n",
      "VISCOFAN\n",
      "-->Datos leidos\n",
      "-->Indice no nulo\n",
      "End of session: file generated: ListaIndices20210403.csv\n"
     ]
    }
   ],
   "source": [
    "ScheduleDayFile()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python390jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.0 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}