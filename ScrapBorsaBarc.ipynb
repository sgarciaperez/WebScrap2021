{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "monthly-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import argparse\n",
    "import csv\n",
    "import pathlib \n",
    "import time\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "developed-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Funcions per obtindre la llista del indexs del Ibex 35 de la borsa de Barcelona\n",
    "\n",
    "# Get Header\n",
    "def getHeaders():   \n",
    "    headers = {\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "               \"Accept-Encoding: gzip, deflate, br\",               \n",
    "               \"Accept-Language: es-ES,es;q=0.8,en-US;q=0.5,en;q=0.3\",  \n",
    "               \"Connection: keep-alive\",                              \n",
    "               \"TE: Trailers\",\n",
    "               \"Upgrade-Insecure-Requests: 1\",\n",
    "               \"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:87.0) Gecko/20100101 Firefox/87.0\"}\n",
    "    return headers\n",
    "\n",
    "\n",
    "# Get table Page        \n",
    "def getPageTable(UrlPage):        \n",
    "    table = None\n",
    "    try:\n",
    "        # Data for post form    \n",
    "        data = {'punto':'indice'}    \n",
    "        page = requests.post(UrlPage,timeout=10)    \n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "        table = soup.find('table', attrs={'id': 'ctl00_Contenido_tblAcciones'})                           \n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"Timeout a la càrrega de la web\")        \n",
    "    except:        \n",
    "        print(\"Error inesperat\")\n",
    "    return table        \n",
    "\n",
    "# Get Firm page and wait x seconds\n",
    "def getFirmTablePage(UrlFirmPage):    \n",
    "    table = None    \n",
    "    try:\n",
    "        t0 = time.time()\n",
    "        # Data for post form            \n",
    "        data = {'punto':'indice'}    \n",
    "        page = requests.get(UrlFirmPage,timeout=10)                    \n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")                \n",
    "        table = soup.find('table', attrs={'id': 'ctl00_Contenido_tblCapital'})                           \n",
    "        # Wait time depending of response\n",
    "        response_delay = time.time() - t0     \n",
    "        time.sleep(10 * response_delay)\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"-->Timeout a la càrrega de dada de la companyia\")                \n",
    "    except:                \n",
    "        print(\"-->Error inesperat: \" +  UrlFirmPage)\n",
    "    return table\n",
    "\n",
    "# Get the list of firm interesting values\n",
    "def getFirmValues(UrlBase,firmPage):\n",
    "    Url = UrlBase+firmPage        \n",
    "    values = []\n",
    "    table = getFirmTablePage(Url)        \n",
    "    if (table is not None):                \n",
    "        nroFila=0\n",
    "        rowNum=0\n",
    "        for row in table.find_all(\"tr\"):\n",
    "            if rowNum==1:\n",
    "                colNum=0                \n",
    "                for cell in row.find_all('td'):\n",
    "                    if colNum==1:\n",
    "                        value=[cell.text,\"\"]              \n",
    "                        values.append(value)                                \n",
    "                        break;\n",
    "                    colNum=colNum+1\n",
    "            rowNum=rowNum+1       \n",
    "    return values    \n",
    "        \n",
    "\n",
    "# Set List with table page values\n",
    "def getIndexs(UrlBase,UrlRef):\n",
    "    indexList = []\n",
    "    UrlIndexPage = UrlBase+UrlRef\n",
    "    table = getPageTable(UrlIndexPage)    \n",
    "    # Extract table values and links\n",
    "    rowList = []\n",
    "    for tr in table.find_all(\"tr\"):        \n",
    "        colList = []               \n",
    "        valuesFirm = []\n",
    "        # Cells Header\n",
    "        cellsHead = tr.findAll('th')                \n",
    "        if ((cellsHead is not None) and (len(cellsHead) > 0)):\n",
    "            for cellHead in cellsHead:        \n",
    "                value = [cellHead.text.strip(),'']                  \n",
    "                colList.append(value)                                                   \n",
    "            colList.append(['Capitalización',''])\n",
    "        else:\n",
    "            # Cells value\n",
    "            cells = tr.findAll('td')                        \n",
    "            for cell in cells:\n",
    "                href = ''\n",
    "                infComp = []\n",
    "                a= cell.find('a')                  \n",
    "                if (a is not None):                 \n",
    "                    href = a.get('href')                                \n",
    "                    # Append / if needed\n",
    "                    if href[0] !='/':\n",
    "                        href = '/' + href                     \n",
    "                    valuesFirm = getFirmValues(UrlBase,href) \n",
    "                    # print firm\n",
    "                    print(cell.text)\n",
    "                value = [cell.text.strip(),href]                                  \n",
    "                colList.append(value)             \n",
    "                \n",
    "        # Extend list with firm information \n",
    "        colList.extend(valuesFirm)\n",
    "        # Append to rowlist    \n",
    "        rowList.append(colList)         \n",
    "    return rowList \n",
    "\n",
    "\n",
    "def writecsv(table,filename):\n",
    "    currentDir = os.path.abspath('')\n",
    "    filePath = os.path.join(currentDir,filename)\n",
    "    file = open(filePath,\"w+\")\n",
    "    for row in table:\n",
    "        for col in row:\n",
    "            file.write(col[0]+\";\")\n",
    "        file.write(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "numerical-enemy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCIONA\n",
      "ACERINOX\n",
      "ACS\n",
      "AENA\n",
      "ALMIRALL\n",
      "AMADEUS\n",
      "ARCELORMIT.\n",
      "B.SANTANDER\n",
      "BA.SABADELL\n",
      "BANKINTER\n",
      "BBVA\n",
      "CAIXABANK\n",
      "CELLNEX\n",
      "CIE AUTOMOT.\n",
      "ENAGAS\n",
      "ENDESA\n",
      "FERROVIAL\n",
      "FLUIDRA\n",
      "GRIFOLS CL.A\n",
      "IAG\n",
      "IBERDROLA\n",
      "INDITEX\n",
      "INDRA A\n",
      "INM.COLONIAL\n",
      "MAPFRE\n",
      "MELIA HOTELS\n",
      "MERLIN\n",
      "NATURGY\n",
      "PHARMA MAR\n",
      "R.E.C.\n",
      "REPSOL\n",
      "SIEMENS GAME\n",
      "SOLARIA\n",
      "TELEFONICA\n",
      "VISCOFAN\n"
     ]
    }
   ],
   "source": [
    "# indicar la ruta\n",
    "urlbase = 'https://www.borsabcn.es'\n",
    "urlRef= '/esp/aspx/Mercados/Precios.aspx?indice=ESI100000000&punto=indice'\n",
    "indexList = getIndexs(urlbase,urlRef);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "duplicate-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "writecsv(indexList,\"ListaIndices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-tennis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
