{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "monthly-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primerament importem totes les llibreries necessaries per completar el projecte.\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import argparse\n",
    "import csv\n",
    "import pathlib \n",
    "import time\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carreguem el fitxer de configuració a la variable config:\n",
    "with open(\"configuration.json\", \"r\") as configFile:\n",
    "    config = json.load(configFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "developed-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcions per obtindre la llista del indexs del Ibex 35 de la borsa de Barcelona\n",
    "\n",
    "# Get Header\n",
    "def getHeaders():   \n",
    "    return config['header']\n",
    "\n",
    "\n",
    "# Get table Page        \n",
    "def getPageTable():        \n",
    "    table = None\n",
    "    try:\n",
    "        # Data for post form    \n",
    "        data = {'punto':'indice'}\n",
    "        page = requests.post(config['URLs']['base'] + config['URLs']['ref'],timeout=10)\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "        table = soup.find('table', attrs={'id': 'ctl00_Contenido_tblAcciones'})\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"Timeout a la càrrega de la web\")\n",
    "    except:        \n",
    "        print(\"Error inesperat\")\n",
    "    return table        \n",
    "\n",
    "# Get Firm page and wait x seconds\n",
    "def getFirmTablePage(UrlFirmPage):    \n",
    "    table = None    \n",
    "    try:\n",
    "        t0 = time.time()\n",
    "        # Data for post form            \n",
    "        data = {'punto':'indice'}    \n",
    "        page = requests.get(UrlFirmPage,timeout=10)                    \n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")                \n",
    "        table = soup.find('table', attrs={'id': 'ctl00_Contenido_tblCapital'})                           \n",
    "        # Wait time depending of response\n",
    "        response_delay = time.time() - t0     \n",
    "        time.sleep(10 * response_delay)\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"-->Timeout a la càrrega de dada de la companyia\")                \n",
    "    except:                \n",
    "        print(\"-->Error inesperat: \" +  UrlFirmPage)\n",
    "    return table\n",
    "\n",
    "# Get the list of firm interesting values\n",
    "def getFirmValue(firmPage): \n",
    "    value = None\n",
    "    table = getFirmTablePage(config['URLs']['base']+firmPage)        \n",
    "    if (table is not None):                \n",
    "        nroFila=0\n",
    "        rowNum=0\n",
    "        for row in table.find_all(\"tr\"):\n",
    "            if rowNum==1:\n",
    "                colNum=0                \n",
    "                for cell in row.find_all('td'):\n",
    "                    if colNum==1:\n",
    "                        value = cell.text                                     \n",
    "                        break;\n",
    "                    colNum=colNum+1\n",
    "            rowNum=rowNum+1       \n",
    "    return value\n",
    "\n",
    "# Get List with column page names\n",
    "def getColNames():\n",
    "    colList = []\n",
    "    table = getPageTable()\n",
    "    for tr in table.find_all(\"tr\"):      \n",
    "        # Cells Header\n",
    "        cellsHead = tr.findAll('th')                \n",
    "        if ((cellsHead is not None) and (len(cellsHead) > 0)):\n",
    "            for cellHead in cellsHead:   \n",
    "                colList.append(cellHead.text.strip())\n",
    "    colList.append('Capitalización')\n",
    "    return colList\n",
    "\n",
    "\n",
    "# Get a pandas dataframe with table page values\n",
    "def getDataframe():\n",
    "    # Obtenció de la taula trobada a la pàgina web amb els valros a extreure\n",
    "    table = getPageTable()    \n",
    "    # Obtenció dels noms de totes els columnes\n",
    "    colList = getColNames()\n",
    "    # variable on es gaurdaran els valors de cada columna\n",
    "    totalValues = []\n",
    "    \n",
    "    # Per cada fila de la taula\n",
    "    for tr in table.find_all(\"tr\"):              \n",
    "        # Es busquen les capçaleres de les columnes\n",
    "        cellsHead = tr.findAll('th')   \n",
    "        # En cas de no tractar-se d'una capçalera:             \n",
    "        if ((cellsHead is None) or (len(cellsHead) == 0)):\n",
    "            # Es busquen totes les cel·les amb valors\n",
    "            cells = tr.findAll('td')\n",
    "            companyValues = []\n",
    "            # Per cada cel·la amb valors, s'afegeix el valor a la llista de companyValues\n",
    "            capitalization = None\n",
    "            for cell in cells:\n",
    "                a= cell.find('a')                  \n",
    "                if (a is not None):                 \n",
    "                    href = a.get('href')\n",
    "                    if href[0] !='/':\n",
    "                        href = '/' + href\n",
    "                    capitalization = getFirmValue(href) \n",
    "                companyValues.append(cell.text.strip())\n",
    "            companyValues.append(capitalization)\n",
    "            # Després d'obtenir tots els valors, els guardo a la llista totalValues fent que finalment\n",
    "            # a la variable totalValues es tingui una llista de valors per a cada fila de la taula que no sigui capçalera\n",
    "            totalValues.append(companyValues)\n",
    "    \n",
    "    # Genero un diccionari on la clau és cadascún dels noms de la capçalera de la taula i el valor una llista buida\n",
    "    dicValues = {}\n",
    "    for colName in colList:\n",
    "        dicValues[colName] = []\n",
    "\n",
    "    # Genero un dataframe amb les capçaleres de la taula com columnes usant el diccionari creat\n",
    "    dataframe = pd.DataFrame(data=dicValues)\n",
    "    # Per cada fila de la taula en format llista:\n",
    "    for list_row in totalValues:\n",
    "        row = {}\n",
    "        index = 0\n",
    "        # Per cada columna (capçalera de la taula), afegeixo al diccionari row el nom de la\n",
    "        # capçalera com a key i el valor de la llista_row pertinent com a value.\n",
    "        for colName in colList:\n",
    "            row[colName] = list_row[index]\n",
    "            index += 1\n",
    "        # Afegeixo el diccionari row com a una nova fila del dataframe\n",
    "        dataframe = dataframe.append(row, ignore_index=True)\n",
    "    # Finalment, retorno el dataframe\n",
    "    return dataframe \n",
    "\n",
    "\n",
    "# Funció que transforma un dataframe de pandas en un fitxer CSV\n",
    "def writeCSV(dataframe, fileName):\n",
    "    # Converteixo el dataframe en format CSV i mostro per pantalla el nom del CSV generat\n",
    "    dataframe.to_csv(fileName, index = False, header=True)\n",
    "    print('New CSV file generated: ' + fileName)\n",
    "\n",
    "\n",
    "# Funció que genera fitxers CSV amb les dades de la web cada 15 minuts fins que es tanca el mercat\n",
    "def ScheduleDayFile():\n",
    "    # En cas de que el mercat no estigui tancat:\n",
    "    while not markedClosed():\n",
    "        # Adquisició del dataframe, generació del nom que tindrà el fitxer CSV i generació d'aquest\n",
    "        # amb la funció wreiteCSV.\n",
    "        dataframe = getDataframe()\n",
    "        fileName = \"ListaIndices\" + time.strftime('%Y-%m-%d_%H-%M')+ \".csv\"\n",
    "        writeCSV(dataframe, fileName)\n",
    "        # Un cop creat i guardat el fixter CSV, ens esperem 15 minuts fins tronar a comprobar l'estat del mercat\n",
    "        print(\"Waiting 15 minutes\")\n",
    "        time.sleep(60*15)        \n",
    "    print(\"End of session: file generated: \" + \"ListaIndices\" + time.strftime('%Y-%m-%d_%H-%M')+ \".csv\")\n",
    "\n",
    "\n",
    "# Retorna un boolean indcant si el mercat està tancat o no\n",
    "def markedClosed():\n",
    "    return (getDataframe()['Hora'].iloc[0] == 'Cierre')\n",
    "\n",
    "    \n",
    "# Save the Stock Exchange one week\n",
    "def ScheduleWeekFiles():    \n",
    "    scheduler = BlockingScheduler()    \n",
    "    scheduler.add_job(job_function, 'cron', day_of_week='mon-fri', hour=9, minute=0)    \n",
    "    scheduler.start()    \n",
    "    \n",
    "\n",
    "# Retorna un dataframe amb els noms de les empreses que formen part de l'Ibex 35 i de les quals tenim dades\n",
    "def getIndex():\n",
    "    return getDataframe()['Nombre']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Nombre', 'Últ.', '% Dif.', 'Máx.', 'Mín.', 'Volumen', 'Efectivo (miles €)', 'Fecha', 'Hora', 'Capitalización']\n"
     ]
    }
   ],
   "source": [
    "print(getColNames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['ACCIONA', 'ACERINOX', 'ACS', 'AENA', 'ALMIRALL', 'AMADEUS', 'ARCELORMIT.', 'B.SANTANDER', 'BA.SABADELL', 'BANKINTER', 'BBVA', 'CAIXABANK', 'CELLNEX', 'CIE AUTOMOT.', 'ENAGAS', 'ENDESA', 'FERROVIAL', 'FLUIDRA', 'GRIFOLS CL.A', 'IAG', 'IBERDROLA', 'INDITEX', 'INDRA A', 'INM.COLONIAL', 'MAPFRE', 'MELIA HOTELS', 'MERLIN', 'NATURGY', 'PHARMA MAR', 'R.E.C.', 'REPSOL', 'SIEMENS GAME', 'SOLARIA', 'TELEFONICA', 'VISCOFAN']\n"
     ]
    }
   ],
   "source": [
    "print(list(getIndex()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "New CSV file generated: ListaIndices2021-04-08_19-14.csv\n",
      "End of session: file generated: ListaIndices2021-04-08_19-15.csv\n"
     ]
    }
   ],
   "source": [
    " ScheduleDayFile()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python390jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.0 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}